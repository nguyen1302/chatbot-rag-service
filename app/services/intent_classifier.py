import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from app.services.embedder import embed_question
from app.services.retriever import retrieve_top_chunks

def classify(question: str) -> str:
    """
    Rule-based intent classifier:
    - Náº¿u chá»©a tá»« khoÃ¡ ná»™i bá»™ â†’ tráº£ 'internal'
    - NgÆ°á»£c láº¡i â†’ 'external'
    """
     # Sá»­ dá»¥ng cáº£ ML model vÃ  keyword-based detection
    ml_intent = predict_intent(question)
    keyword_intent = detect_question_type(question)
    
    print(f"[ML INTENT]: {ml_intent}")
    print(f"[KEYWORD INTENT]: {keyword_intent}")
    
    # Quyáº¿t Ä‘á»‹nh intent cuá»‘i cÃ¹ng
    if keyword_intent == "hybrid":
        final_intent = "hybrid"
    elif keyword_intent == ml_intent:
        final_intent = keyword_intent
    elif keyword_intent == "internal" and ml_intent == "external":
        final_intent = "internal"
    elif keyword_intent == "external" and ml_intent == "internal":
        final_intent = "external"
    else:
        final_intent = ml_intent
    return final_intent


# --- Äá»ŒC Dá»® LIá»†U Ã Äá»ŠNH ---
with open("./data_train_in_ex/internal.txt", "r", encoding="utf-8") as f:
    internal_data = [(line.strip(), "internal") for line in f.readlines() if line.strip()]

with open("./data_train_in_ex/external.txt", "r", encoding="utf-8") as f:
    external_data = [(line.strip(), "external") for line in f.readlines() if line.strip()]

data = internal_data + external_data
df = pd.DataFrame(data, columns=["text", "label"])

pipeline = Pipeline([
    ("tfidf", TfidfVectorizer()),
    ("clf", LogisticRegression())
])
pipeline.fit(df["text"], df["label"])


#dá»±a Ä‘oÃ¡n báº±ng mÃ´ hÃ¬nh lr
def predict_intent(question):
    return pipeline.predict([question])[0]

def detect_question_type(user_input):
    user_input_lower = user_input.lower()
    
    # Tá»« khÃ³a ná»™i bá»™ vá»›i trá»ng sá»‘ (tá»« tÃ i liá»‡u giá»›i thiá»‡u + mÃ´ táº£ sáº£n pháº©m)
    internal_keywords = {
        # Sáº£n pháº©m & há»‡ thá»‘ng chÃ­nh â€“ trá»ng sá»‘ cao
        "lms360": 4, "qlth": 4, "bÃ¡ch khoa": 4, "kiá»ƒm Ä‘á»‹nh cháº¥t lÆ°á»£ng": 4, "thi Ä‘ua khen thÆ°á»Ÿng": 4,
        "há»‡ sinh thÃ¡i": 3, "sáº£n pháº©m": 3, "truyá»n thÃ´ng ná»™i bá»™": 3, "há»c liá»‡u sá»‘": 3,
        "chá»¯ kÃ½ sá»‘": 3, "kho há»c liá»‡u": 3, "phÃ²ng thÃ­ nghiá»‡m mÃ´ phá»ng": 3, "há»‡ thá»‘ng kiá»ƒm Ä‘á»‹nh": 3,
        "thi Ä‘ua": 3, "khen thÆ°á»Ÿng": 3, "tá»± Ä‘Ã¡nh giÃ¡": 3, "chuyá»ƒn Ä‘á»•i sá»‘": 3,
        "Ä‘Ã o táº¡o nhÃ¢n lá»±c sá»‘": 3, "há»c báº¡ sá»‘": 3, "giáº£i phÃ¡p sá»‘ hÃ³a": 3,
        "ngÃ¢n hÃ ng há»c liá»‡u": 3, "trÃ­ tuá»‡ nhÃ¢n táº¡o": 3, "giÃ¡m sÃ¡t há»c táº­p": 3,
        "phÃ¢n tÃ­ch káº¿t quáº£ há»c táº­p": 3, "chuyá»ƒn Ä‘á»•i phÆ°Æ¡ng phÃ¡p giáº£ng dáº¡y": 3,

        # TÃ­nh nÄƒng sáº£n pháº©m â€“ trá»ng sá»‘ trung bÃ¬nh
        "Ä‘iá»ƒm danh thÃ´ng minh": 2, "phá»¥ huynh": 2, "giÃ¡o viÃªn": 2, "há»c sinh": 2,"há»‡ thá»‘ng":2,
        "bÃ i giáº£ng sá»‘": 2, "ai bk": 2, "chatbot ai": 2, "cháº¥m Ä‘iá»ƒm tá»± Ä‘á»™ng": 2,
        "kiá»ƒm tra Ä‘Ã¡nh giÃ¡": 2, "trá»™n Ä‘á»": 2, "camera ai": 2, "Ä‘iá»ƒm sá»‘": 2,
        "quáº£n lÃ½ lá»›p há»c": 2, "thá»‘ng kÃª bÃ¡o cÃ¡o": 2, "á»©ng dá»¥ng ai": 2, "phÃ¢n tÃ­ch há»c táº­p": 2,
        "chatbot bk": 2, "thÃ­ nghiá»‡m mÃ´ phá»ng": 2, "cháº¥m Ä‘iá»ƒm ai": 2, "soáº¡n giáº£ng tá»± Ä‘á»™ng": 2,
        "trÃ¬nh chiáº¿u bÃ i giáº£ng": 2, "gá»£i Ã½ há»c táº­p": 2, "nháº¯c nhá»Ÿ há»c táº­p": 2, "Ä‘Äƒng nháº­p vnedi": 2,
        "bÃ¡o cÃ¡o há»c táº­p": 2, "tá»± luáº­n": 2, "tráº¯c nghiá»‡m": 2, "Ä‘iá»n khuyáº¿t": 2,
        "giao tiáº¿p hai chiá»u": 2, "thá»i khÃ³a biá»ƒu tá»± Ä‘á»™ng": 2, "chá»¯ kÃ½ sá»‘ há»c báº¡": 2,
        "y táº¿ há»c Ä‘Æ°á»ng": 2, "bmi": 2, "trá»±c tuyáº¿n káº¿t há»£p trá»±c tiáº¿p": 2,
        "phÃª duyá»‡t há»c báº¡": 2, "gá»­i há»c báº¡ Ä‘iá»‡n tá»­": 2, "thi thá»­ thpt": 2,"há»c táº­p":2 ,"bÃ i giáº£ng":2,

        # Thuá»™c tÃ­nh thÆ°Æ¡ng hiá»‡u / tá»• chá»©c â€“ trá»ng sá»‘ tháº¥p
        "táº­p Ä‘oÃ n": 1, "cÃ´ng ty": 1, "giá»›i thiá»‡u": 1, "quá»‘c tháº¯ng": 1, "táº§m nhÃ¬n": 1, "sá»© má»‡nh": 1,
        "ar": 1, "vr": 1, "blockchain": 1, "huá»³nh quá»‘c tháº¯ng": 1, "bá»n vá»¯ng": 1,
        "há»£p tÃ¡c quá»‘c táº¿": 1, "tÆ° duy pháº£n biá»‡n": 1, "giáº£i quyáº¿t váº¥n Ä‘á»": 1,
        "an sinh tinh tháº§n": 1, "Ä‘á»•i má»›i sÃ¡ng táº¡o": 1, "mÃ´ hÃ¬nh blended learning": 1,
        "giÃ¡o dá»¥c cÃ¡ nhÃ¢n hÃ³a": 1, "á»©ng dá»¥ng cÃ´ng nghá»‡": 1
    }


    # Tá»« khÃ³a external giá»¯ nguyÃªn (hoáº·c bá»• sung sau náº¿u cáº§n)
    external_keywords = {
        # Comparison indicators â€“ high weight
        "so sÃ¡nh": 3, "khÃ¡c biá»‡t": 3, "tÆ°Æ¡ng tá»±": 3, "khÃ¡c gÃ¬": 3,
        "giá»‘ng": 2, "khÃ¡c nhau": 2,

        # Ownership/external info â€“ high weight
        "thuá»™c vá»": 3, "sá»Ÿ há»¯u": 3, "cá»§a ai": 3,
        "google": 2, "microsoft": 2, "moodle": 2,
        "sá»Ÿ giÃ¡o dá»¥c": 2, "phÃ²ng giÃ¡o dá»¥c": 2, "bá»™ gd&Ä‘t": 2,

        # Academic subjects â€“ medium weight
        "toÃ¡n": 2, "phÆ°Æ¡ng trÃ¬nh": 2, "Ä‘áº¡o hÃ m": 2, "tÃ­ch phÃ¢n": 2,
        "xÃ¡c suáº¥t": 2, "Ä‘áº¡i sá»‘": 2, "hÃ¬nh há»c": 2, "logarit": 2,
        "váº­t lÃ½": 2, "hÃ³a há»c": 2, "sinh há»c": 2, "di truyá»n": 2,
        "cÆ¡ há»c": 2, "nhiá»‡t há»c": 2, "quang há»c": 2, "lá»±c": 2,
        "giÃ¡o dá»¥c Ä‘á»‹a phÆ°Æ¡ng": 2, "ngá»¯ vÄƒn": 2, "tiáº¿ng anh": 2,

        # Education-related concepts â€“ medium weight
        "trÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬": 2, "blockchain": 2, "cÃ´ng nghá»‡ thÃ´ng tin": 2,
        "ngÃ´n ngá»¯ láº­p trÃ¬nh": 2, "python": 2, "chatgpt": 2, "machine learning": 2,
        "há»c mÃ¡y": 2, "deep learning": 2, "neural network": 2,
        "blended learning": 2, "e-learning": 2, "bÃ i giáº£ng trá»±c tuyáº¿n": 2,
        "á»©ng dá»¥ng ai trong giÃ¡o dá»¥c": 2,"trá»±c quan":2,

        # General knowledge â€“ low weight
        "thá»i tiáº¿t": 1, "quá»‘c gia": 1, "tá»•ng thá»‘ng": 1, "tháº¿ giá»›i": 1,
        "lá»‹ch sá»­": 1, "Ä‘á»‹nh nghÄ©a": 1, "giáº£i thÃ­ch": 1, "pt": 1,
        "báº­c": 1, "cÄƒn": 1, "tÃ­nh": 1, "á»©ng dá»¥ng": 1,
        "kiáº¿n thá»©c chung": 1, "giáº£i toÃ¡n": 1, "cÃ¡ch giáº£i": 1,
        "giá»›i háº¡n": 1, "vector": 1, "ma tráº­n": 1, "thá»‘ng kÃª": 1,
        "Ä‘á»“ thá»‹": 1, "hÃ m sá»‘": 1, "chu vi": 1, "diá»‡n tÃ­ch": 1,
        "nÄƒng lÆ°á»£ng": 1, "Ä‘á»™ng nÄƒng": 1, "tháº¿ nÄƒng": 1, "pháº£n á»©ng": 1,
        "phÃ¢n tá»­": 1, "nguyÃªn tá»­": 1
    }


    # TÃ­nh Ä‘iá»ƒm trá»ng sá»‘
    internal_score = sum(weight for keyword, weight in internal_keywords.items() 
                         if keyword in user_input_lower)
    external_score = sum(weight for keyword, weight in external_keywords.items() 
                         if keyword in user_input_lower)

    print(f"ğŸ” PhÃ¢n tÃ­ch: Internal_score={internal_score}, External_score={external_score}")
    
    # Logic quyáº¿t Ä‘á»‹nh Ã½ Ä‘á»‹nh
    if internal_score >= 2 and external_score >= 2:
        return "hybrid"
    elif internal_score >= 1 and external_score >= 3:
        return "hybrid"
    elif internal_score > external_score:
        return "internal"
    elif external_score > 0:
        return "external"
    else:
        return ""
    

def check_question_followup(question):
    follow_up_indicators = [
        # Äáº¡i tá»« chá»‰ Ä‘á»‹nh
        "nÃ³", "nÃ y", "Ä‘Ã³", "chÃºng", "cÃ¡i nÃ y", "cÃ¡i Ä‘Ã³", "viá»‡c nÃ y", "viá»‡c Ä‘Ã³",
        "trÆ°á»ng há»£p nÃ y", "trÆ°á»ng há»£p Ä‘Ã³", "há»‡ thá»‘ng nÃ y", "há»‡ thá»‘ng Ä‘Ã³", "há»", "sáº£n pháº©m nÃ y", "á»©ng dá»¥ng nÃ y",

        # Há»i vá» tÃ­nh nÄƒng/Ä‘áº·c Ä‘iá»ƒm/chi tiáº¿t
        "lÃ m gÃ¬", "dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬", "cÃ³ tÃ¡c dá»¥ng gÃ¬", "dÃ¹ng nhÆ° tháº¿ nÃ o", "cÃ³ chá»©c nÄƒng gÃ¬",
        "tÃ­nh nÄƒng", "chá»©c nÄƒng", "hoáº¡t Ä‘á»™ng", "cÃ¡ch váº­n hÃ nh", "cÃ¡ch dÃ¹ng",
        "Ä‘áº·c Ä‘iá»ƒm", "cáº¥u trÃºc", "cÆ¡ cháº¿", "Æ°u Ä‘iá»ƒm", "nhÆ°á»£c Ä‘iá»ƒm",
        "Ã¡p dá»¥ng nhÆ° tháº¿ nÃ o", "triá»ƒn khai tháº¿ nÃ o", "váº­n hÃ nh tháº¿ nÃ o", "tÃ­ch há»£p ra sao",

        # Há»i chi tiáº¿t, má»Ÿ rá»™ng
        "giáº£i thÃ­ch thÃªm", "giáº£i thÃ­ch rÃµ", "nÃ³i rÃµ hÆ¡n", "chi tiáº¿t hÆ¡n", "cá»¥ thá»ƒ hÆ¡n",
        "vÃ­ dá»¥", "minh há»a", "mÃ´ phá»ng", "cho vÃ­ dá»¥", "demo", "mÃ´ táº£ thÃªm",
        "trÆ°á»ng há»£p cá»¥ thá»ƒ", "thá»±c táº¿ triá»ƒn khai", "á»©ng dá»¥ng thá»±c táº¿",

        # So sÃ¡nh
        "khÃ¡c gÃ¬", "giá»‘ng gÃ¬", "so vá»›i", "tÆ°Æ¡ng tá»±", "khÃ¡c nhau chá»— nÃ o", "giá»‘ng nhau chá»— nÃ o",
        "Ä‘iá»ƒm khÃ¡c biá»‡t", "Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng", "cÃ³ gÃ¬ khÃ¡c", "cÃ³ gÃ¬ giá»‘ng",

        # Gá»£i Ã½ follow-up theo ngá»¯ cáº£nh liÃªn tá»¥c
        "tiáº¿p theo thÃ¬ sao", "trong trÆ°á»ng há»£p Ä‘Ã³", "sau Ä‘Ã³", "váº­y tiáº¿p theo", "tiáº¿p theo lÃ m gÃ¬",
        "káº¿ tiáº¿p lÃ  gÃ¬", "sau bÆ°á»›c Ä‘Ã³", "sau bÆ°á»›c nÃ y", "tiáº¿p Ä‘áº¿n", "náº¿u váº­y thÃ¬ sao"
    ]

    has_follow_up = any(indicator in question.lower() for indicator in follow_up_indicators)
    
    return has_follow_up


